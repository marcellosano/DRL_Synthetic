{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# \ud83c\udf0a DRL Coastal Emergency Warning System - Colab Training\n",
    "\n",
    "Train DRL agents with free GPU acceleration on Google Colab.\n",
    "\n",
    "**Features:**\n",
    "- \u2705 Automatic setup from GitHub\n",
    "- \u2705 Free Tesla T4 GPU (15-30 min training)\n",
    "- \u2705 Uses your existing configuration files\n",
    "- \u2705 Download trained models\n",
    "- \u2705 Compatible with local dashboard\n",
    "\n",
    "**Workflow:**\n",
    "1. Configure experiment locally (dashboard)\n",
    "2. Push config to GitHub\n",
    "3. Run training on Colab (this notebook)\n",
    "4. Download checkpoint\n",
    "5. Evaluate locally (dashboard)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## \ud83d\udce6 Setup & Installation\n",
    "\n",
    "Run this cell first to clone repo and install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Clone repository\n",
    "import os\n",
    "if os.path.exists('DRL_Synthetic'):\n",
    "    print(\"\u2705 Repository already cloned\")\n",
    "else:\n",
    "    !git clone https://github.com/marcellosano/DRL_Synthetic.git\n",
    "    print(\"\u2705 Repository cloned\")\n",
    "\n",
    "# Change to repo directory\n",
    "os.chdir('/content/DRL_Synthetic')\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Install dependencies\n",
    "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118 -q\n",
    "!pip install numpy pandas matplotlib seaborn scikit-learn pyyaml -q\n",
    "\n",
    "print(\"\\n\u2705 Setup complete!\")\n",
    "\n",
    "# Check GPU\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\n\ud83d\ude80 GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"\\n\u26a0\ufe0f  No GPU available. Training will be slow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config-header"
   },
   "source": [
    "## \u2699\ufe0f Configuration\n",
    "\n",
    "Select which configuration to train with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config-selection"
   },
   "outputs": [],
   "source": [
    "# Load configuration with manual inheritance handling\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "def load_config_with_inheritance(config_path):\n",
    "    \"\"\"Load YAML config and resolve 'extends' inheritance\"\"\"\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    # Handle inheritance\n",
    "    if 'extends' in config:\n",
    "        parent_path = Path(config_path).parent / config['extends']\n",
    "        parent_config = load_config_with_inheritance(str(parent_path))\n",
    "        \n",
    "        # Merge: parent first, then child overrides\n",
    "        def merge_dicts(parent, child):\n",
    "            result = parent.copy()\n",
    "            for key, value in child.items():\n",
    "                if key == 'extends':\n",
    "                    continue\n",
    "                if key in result and isinstance(result[key], dict) and isinstance(value, dict):\n",
    "                    result[key] = merge_dicts(result[key], value)\n",
    "                else:\n",
    "                    result[key] = value\n",
    "            return result\n",
    "        \n",
    "        config = merge_dicts(parent_config, config)\n",
    "        config.pop('extends', None)\n",
    "    \n",
    "    return config\n",
    "\n",
    "# Available configurations\n",
    "CONFIGS = {\n",
    "    'quick_test': 'config/experiments/quick_test.yaml',\n",
    "    'reward_tuning': 'config/experiments/reward_tuning.yaml',\n",
    "    'hyperparameter_sweep': 'config/experiments/hyperparameter_sweep.yaml',\n",
    "    'base': 'config/base.yaml',\n",
    "}\n",
    "\n",
    "# SELECT YOUR CONFIG HERE\n",
    "selected_config = 'quick_test'\n",
    "\n",
    "config_path = CONFIGS[selected_config]\n",
    "print(f\"\ud83d\udccb Selected configuration: {selected_config}\")\n",
    "print(f\"   Path: {config_path}\")\n",
    "\n",
    "# Load config with inheritance\n",
    "config = load_config_with_inheritance(config_path)\n",
    "\n",
    "print(f\"\\n\ud83c\udfaf Training Settings:\")\n",
    "print(f\"   Episodes: {config['training']['episodes']}\")\n",
    "print(f\"   Batch Size: {config['training']['batch_size']}\")\n",
    "print(f\"   Learning Rate: {config['training']['learning_rate']}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcb0 Reward Weights:\")\n",
    "print(f\"   Lives Saved: {config['reward']['lives_saved_weight']}\")\n",
    "print(f\"   Early Warning Bonus: {config['reward']['early_warning_bonus']}\")\n",
    "print(f\"   False Alarm Penalty: {config['reward']['false_alarm_penalty']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train-header"
   },
   "source": [
    "## \ud83d\ude80 Training\n",
    "\n",
    "Run training with progress updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training"
   },
   "outputs": [],
   "source": [
    "from dashboard.utils.trainer import TrainingSession\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "# Create training session\n",
    "print(\"\ud83c\udf93 Initializing training session...\")\n",
    "session = TrainingSession(config_path, run_name=f\"colab_{selected_config}\")\n",
    "\n",
    "print(f\"\u2705 Training session created: {session.run.name}\")\n",
    "print(f\"   Run directory: {session.run_dir}\")\n",
    "print(f\"   Total episodes: {session.total_episodes}\")\n",
    "print(f\"\\n\ud83d\ude80 Starting training...\\n\")\n",
    "\n",
    "# Add callback for progress updates\n",
    "def progress_callback(metrics):\n",
    "    \"\"\"Display training progress\"\"\"\n",
    "    episode = metrics['episode']\n",
    "    if episode % 10 == 0 or episode < 10:\n",
    "        clear_output(wait=True)\n",
    "        progress = (episode / session.total_episodes) * 100\n",
    "        \n",
    "        print(f\"\ud83c\udf93 Training Progress: {progress:.1f}%\")\n",
    "        print(f\"   Episode: {episode}/{session.total_episodes}\")\n",
    "        print(f\"   Reward: {metrics.get('reward', 0):.2f}\")\n",
    "        print(f\"   Lives Lost: {metrics.get('lives_lost', 0)}\")\n",
    "        print(f\"   Policy Loss: {metrics.get('policy_loss', 0):.4f}\")\n",
    "        print(f\"   Value Loss: {metrics.get('value_loss', 0):.4f}\")\n",
    "        print(f\"\\n{'\u2588' * int(progress/2)}{'\u2591' * (50-int(progress/2))}\")\n",
    "\n",
    "session.add_callback(progress_callback)\n",
    "\n",
    "# Train\n",
    "start_time = time.time()\n",
    "session.train()\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\n\u2705 Training complete!\")\n",
    "print(f\"   Total time: {elapsed/60:.1f} minutes\")\n",
    "print(f\"   Episodes: {session.total_episodes}\")\n",
    "print(f\"   Final reward: {session.metrics['episode_rewards'][-1]:.2f}\")\n",
    "print(f\"   Average reward (last 100): {sum(session.metrics['episode_rewards'][-100:])/100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results-header"
   },
   "source": [
    "## \ud83d\udcca Training Results\n",
    "\n",
    "Visualize training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "results-viz"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Training Results', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Episode Rewards\n",
    "ax1 = axes[0, 0]\n",
    "episodes = list(range(len(session.metrics['episode_rewards'])))\n",
    "rewards = session.metrics['episode_rewards']\n",
    "ax1.plot(episodes, rewards, alpha=0.3, label='Reward')\n",
    "if len(rewards) >= 10:\n",
    "    ma = np.convolve(rewards, np.ones(10)/10, mode='valid')\n",
    "    ax1.plot(range(len(ma)), ma, linewidth=2, label='MA(10)')\n",
    "ax1.set_xlabel('Episode')\n",
    "ax1.set_ylabel('Reward')\n",
    "ax1.set_title('Episode Rewards')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Lives Lost\n",
    "ax2 = axes[0, 1]\n",
    "lives_lost = session.metrics['lives_lost']\n",
    "ax2.plot(episodes, lives_lost, color='red', linewidth=2)\n",
    "ax2.set_xlabel('Episode')\n",
    "ax2.set_ylabel('Lives Lost')\n",
    "ax2.set_title('Lives Lost per Episode')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Policy Loss\n",
    "ax3 = axes[1, 0]\n",
    "if session.metrics['policy_loss']:\n",
    "    ax3.plot(episodes, session.metrics['policy_loss'], color='orange', linewidth=2)\n",
    "    ax3.set_xlabel('Episode')\n",
    "    ax3.set_ylabel('Loss')\n",
    "    ax3.set_title('Policy Loss')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Cumulative Damage\n",
    "ax4 = axes[1, 1]\n",
    "if session.metrics['cumulative_damage']:\n",
    "    ax4.plot(episodes, session.metrics['cumulative_damage'], color='purple', linewidth=2)\n",
    "    ax4.set_xlabel('Episode')\n",
    "    ax4.set_ylabel('Damage ($)')\n",
    "    ax4.set_title('Cumulative Damage')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\ud83d\udcc8 Training Summary:\")\n",
    "print(f\"   Mean Reward: {np.mean(rewards):.2f} \u00b1 {np.std(rewards):.2f}\")\n",
    "print(f\"   Mean Lives Lost: {np.mean(lives_lost):.1f} \u00b1 {np.std(lives_lost):.1f}\")\n",
    "print(f\"   Best Reward: {max(rewards):.2f} (Episode {rewards.index(max(rewards))})\")\n",
    "print(f\"   Worst Reward: {min(rewards):.2f} (Episode {rewards.index(min(rewards))})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-header"
   },
   "source": [
    "## \ud83d\udcbe Download Results\n",
    "\n",
    "Download trained model and metrics to use in local dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "print(\"\ud83d\udce6 Preparing files for download...\")\n",
    "\n",
    "# Create download package\n",
    "download_dir = f\"colab_results_{session.run.name}\"\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# Copy checkpoint\n",
    "checkpoint_path = session.checkpoint_dir / \"final.pt\"\n",
    "if checkpoint_path.exists():\n",
    "    shutil.copy(checkpoint_path, f\"{download_dir}/model.pt\")\n",
    "    print(f\"   \u2705 Checkpoint copied: model.pt\")\n",
    "\n",
    "# Copy metrics\n",
    "if session.metrics_file.exists():\n",
    "    shutil.copy(session.metrics_file, f\"{download_dir}/metrics.json\")\n",
    "    print(f\"   \u2705 Metrics copied: metrics.json\")\n",
    "\n",
    "# Copy config\n",
    "config_snapshot = session.run_dir / \"config.yaml\"\n",
    "if config_snapshot.exists():\n",
    "    shutil.copy(config_snapshot, f\"{download_dir}/config.yaml\")\n",
    "    print(f\"   \u2705 Config copied: config.yaml\")\n",
    "\n",
    "# Create summary\n",
    "summary = {\n",
    "    'run_name': session.run.name,\n",
    "    'config': selected_config,\n",
    "    'episodes': session.total_episodes,\n",
    "    'training_time_minutes': elapsed / 60,\n",
    "    'final_reward': session.metrics['episode_rewards'][-1],\n",
    "    'mean_reward': float(np.mean(session.metrics['episode_rewards'])),\n",
    "    'mean_lives_lost': float(np.mean(session.metrics['lives_lost'])),\n",
    "}\n",
    "with open(f\"{download_dir}/summary.json\", 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(f\"   \u2705 Summary created: summary.json\")\n",
    "\n",
    "# Create zip file\n",
    "print(\"\\n\ud83d\udddc\ufe0f  Creating zip archive...\")\n",
    "shutil.make_archive(download_dir, 'zip', download_dir)\n",
    "zip_file = f\"{download_dir}.zip\"\n",
    "\n",
    "print(f\"\\n\u2705 Package ready: {zip_file}\")\n",
    "print(f\"   Size: {os.path.getsize(zip_file) / 1e6:.1f} MB\")\n",
    "\n",
    "# Download\n",
    "print(\"\\n\ud83d\udce5 Downloading...\")\n",
    "files.download(zip_file)\n",
    "\n",
    "print(\"\\n\u2705 Download complete!\")\n",
    "print(\"\\n\ud83d\udccb Next Steps:\")\n",
    "print(\"   1. Extract the zip file locally\")\n",
    "print(\"   2. Copy model.pt to your runs directory\")\n",
    "print(\"   3. Open dashboard \u2192 Evaluation \u2192 Load model.pt\")\n",
    "print(\"   4. Run evaluation and compare with other models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch-header"
   },
   "source": [
    "## \ud83d\udd04 Batch Training (Optional)\n",
    "\n",
    "Train multiple configurations in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch-training"
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: Train multiple configs\n",
    "# Uncomment and modify as needed\n",
    "\n",
    "# configs_to_train = [\n",
    "#     'config/experiments/quick_test.yaml',\n",
    "#     'config/experiments/reward_tuning.yaml',\n",
    "# ]\n",
    "\n",
    "# for config_path in configs_to_train:\n",
    "#     print(f\"\\n{'='*60}\")\n",
    "#     print(f\"Training: {config_path}\")\n",
    "#     print(f\"{'='*60}\\n\")\n",
    "#     \n",
    "#     session = TrainingSession(config_path)\n",
    "#     session.add_callback(progress_callback)\n",
    "#     session.train()\n",
    "#     \n",
    "#     print(f\"\u2705 Completed: {session.run.name}\")\n",
    "#     print(f\"   Final reward: {session.metrics['episode_rewards'][-1]:.2f}\")\n",
    "\n",
    "print(\"Batch training cell (commented out by default)\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}