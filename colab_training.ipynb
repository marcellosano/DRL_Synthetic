{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üåä DRL Coastal Emergency Warning System - Colab Training\n",
    "\n",
    "Train DRL agents with free GPU acceleration on Google Colab.\n",
    "\n",
    "**Features:**\n",
    "- ‚úÖ Automatic setup from GitHub\n",
    "- ‚úÖ Free Tesla T4 GPU (15-30 min training)\n",
    "- ‚úÖ Uses your existing configuration files\n",
    "- ‚úÖ Download trained models\n",
    "- ‚úÖ Compatible with local dashboard\n",
    "\n",
    "**Workflow:**\n",
    "1. Configure experiment locally (dashboard)\n",
    "2. Push config to GitHub\n",
    "3. Run training on Colab (this notebook)\n",
    "4. Download checkpoint\n",
    "5. Evaluate locally (dashboard)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## üì¶ Setup & Installation\n",
    "\n",
    "Run this cell first to clone repo and install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Clone repository\n",
    "import os\n",
    "if os.path.exists('DRL_Synthetic'):\n",
    "    print(\"‚úÖ Repository already cloned\")\n",
    "else:\n",
    "    !git clone https://github.com/marcellosano/DRL_Synthetic.git\n",
    "    print(\"‚úÖ Repository cloned\")\n",
    "\n",
    "%cd DRL_Synthetic\n",
    "\n",
    "# Install dependencies\n",
    "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118 -q\n",
    "!pip install numpy pandas matplotlib seaborn scikit-learn pyyaml -q\n",
    "\n",
    "print(\"\\n‚úÖ Setup complete!\")\n",
    "\n",
    "# Check GPU\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\nüöÄ GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No GPU available. Training will be slow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config-header"
   },
   "source": [
    "## ‚öôÔ∏è Configuration\n",
    "\n",
    "Select which configuration to train with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config-selection"
   },
   "outputs": [],
   "source": [
    "# Available configurations\n",
    "CONFIGS = {\n",
    "    'quick_test': 'config/experiments/quick_test.yaml',\n",
    "    'reward_tuning': 'config/experiments/reward_tuning.yaml',\n",
    "    'hyperparameter_sweep': 'config/experiments/hyperparameter_sweep.yaml',\n",
    "    'base': 'config/base.yaml',\n",
    "}\n",
    "\n",
    "# SELECT YOUR CONFIG HERE\n",
    "selected_config = 'quick_test'  # Change this to train different configs\n",
    "\n",
    "config_path = CONFIGS[selected_config]\n",
    "print(f\"üìã Selected configuration: {selected_config}\")\n",
    "print(f\"   Path: {config_path}\")\n",
    "\n",
    "# Display configuration\n",
    "import yaml\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"\\nüéØ Training Settings:\")\n",
    "print(f\"   Episodes: {config['training']['episodes']}\")\n",
    "print(f\"   Batch Size: {config['training']['batch_size']}\")\n",
    "print(f\"   Learning Rate: {config['training']['learning_rate']}\")\n",
    "print(f\"\\nüí∞ Reward Weights:\")\n",
    "print(f\"   Lives Saved: {config['reward']['lives_saved_weight']}\")\n",
    "print(f\"   Early Warning Bonus: {config['reward']['early_warning_bonus']}\")\n",
    "print(f\"   False Alarm Penalty: {config['reward']['false_alarm_penalty']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train-header"
   },
   "source": [
    "## üöÄ Training\n",
    "\n",
    "Run training with progress updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training"
   },
   "outputs": [],
   "source": [
    "from dashboard.utils.trainer import TrainingSession\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "# Create training session\n",
    "print(\"üéì Initializing training session...\")\n",
    "session = TrainingSession(config_path, run_name=f\"colab_{selected_config}\")\n",
    "\n",
    "print(f\"‚úÖ Training session created: {session.run.name}\")\n",
    "print(f\"   Run directory: {session.run_dir}\")\n",
    "print(f\"   Total episodes: {session.total_episodes}\")\n",
    "print(f\"\\nüöÄ Starting training...\\n\")\n",
    "\n",
    "# Add callback for progress updates\n",
    "def progress_callback(metrics):\n",
    "    \"\"\"Display training progress\"\"\"\n",
    "    episode = metrics['episode']\n",
    "    if episode % 10 == 0 or episode < 10:\n",
    "        clear_output(wait=True)\n",
    "        progress = (episode / session.total_episodes) * 100\n",
    "        \n",
    "        print(f\"üéì Training Progress: {progress:.1f}%\")\n",
    "        print(f\"   Episode: {episode}/{session.total_episodes}\")\n",
    "        print(f\"   Reward: {metrics.get('reward', 0):.2f}\")\n",
    "        print(f\"   Lives Lost: {metrics.get('lives_lost', 0)}\")\n",
    "        print(f\"   Policy Loss: {metrics.get('policy_loss', 0):.4f}\")\n",
    "        print(f\"   Value Loss: {metrics.get('value_loss', 0):.4f}\")\n",
    "        print(f\"\\n{'‚ñà' * int(progress/2)}{'‚ñë' * (50-int(progress/2))}\")\n",
    "\n",
    "session.add_callback(progress_callback)\n",
    "\n",
    "# Train\n",
    "start_time = time.time()\n",
    "session.train()\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Training complete!\")\n",
    "print(f\"   Total time: {elapsed/60:.1f} minutes\")\n",
    "print(f\"   Episodes: {session.total_episodes}\")\n",
    "print(f\"   Final reward: {session.metrics['episode_rewards'][-1]:.2f}\")\n",
    "print(f\"   Average reward (last 100): {sum(session.metrics['episode_rewards'][-100:])/100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results-header"
   },
   "source": [
    "## üìä Training Results\n",
    "\n",
    "Visualize training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "results-viz"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Training Results', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Episode Rewards\n",
    "ax1 = axes[0, 0]\n",
    "episodes = list(range(len(session.metrics['episode_rewards'])))\n",
    "rewards = session.metrics['episode_rewards']\n",
    "ax1.plot(episodes, rewards, alpha=0.3, label='Reward')\n",
    "if len(rewards) >= 10:\n",
    "    ma = np.convolve(rewards, np.ones(10)/10, mode='valid')\n",
    "    ax1.plot(range(len(ma)), ma, linewidth=2, label='MA(10)')\n",
    "ax1.set_xlabel('Episode')\n",
    "ax1.set_ylabel('Reward')\n",
    "ax1.set_title('Episode Rewards')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Lives Lost\n",
    "ax2 = axes[0, 1]\n",
    "lives_lost = session.metrics['lives_lost']\n",
    "ax2.plot(episodes, lives_lost, color='red', linewidth=2)\n",
    "ax2.set_xlabel('Episode')\n",
    "ax2.set_ylabel('Lives Lost')\n",
    "ax2.set_title('Lives Lost per Episode')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Policy Loss\n",
    "ax3 = axes[1, 0]\n",
    "if session.metrics['policy_loss']:\n",
    "    ax3.plot(episodes, session.metrics['policy_loss'], color='orange', linewidth=2)\n",
    "    ax3.set_xlabel('Episode')\n",
    "    ax3.set_ylabel('Loss')\n",
    "    ax3.set_title('Policy Loss')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Cumulative Damage\n",
    "ax4 = axes[1, 1]\n",
    "if session.metrics['cumulative_damage']:\n",
    "    ax4.plot(episodes, session.metrics['cumulative_damage'], color='purple', linewidth=2)\n",
    "    ax4.set_xlabel('Episode')\n",
    "    ax4.set_ylabel('Damage ($)')\n",
    "    ax4.set_title('Cumulative Damage')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nüìà Training Summary:\")\n",
    "print(f\"   Mean Reward: {np.mean(rewards):.2f} ¬± {np.std(rewards):.2f}\")\n",
    "print(f\"   Mean Lives Lost: {np.mean(lives_lost):.1f} ¬± {np.std(lives_lost):.1f}\")\n",
    "print(f\"   Best Reward: {max(rewards):.2f} (Episode {rewards.index(max(rewards))})\")\n",
    "print(f\"   Worst Reward: {min(rewards):.2f} (Episode {rewards.index(min(rewards))})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-header"
   },
   "source": [
    "## üíæ Download Results\n",
    "\n",
    "Download trained model and metrics to use in local dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "print(\"üì¶ Preparing files for download...\")\n",
    "\n",
    "# Create download package\n",
    "download_dir = f\"colab_results_{session.run.name}\"\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# Copy checkpoint\n",
    "checkpoint_path = session.checkpoint_dir / \"final.pt\"\n",
    "if checkpoint_path.exists():\n",
    "    shutil.copy(checkpoint_path, f\"{download_dir}/model.pt\")\n",
    "    print(f\"   ‚úÖ Checkpoint copied: model.pt\")\n",
    "\n",
    "# Copy metrics\n",
    "if session.metrics_file.exists():\n",
    "    shutil.copy(session.metrics_file, f\"{download_dir}/metrics.json\")\n",
    "    print(f\"   ‚úÖ Metrics copied: metrics.json\")\n",
    "\n",
    "# Copy config\n",
    "config_snapshot = session.run_dir / \"config.yaml\"\n",
    "if config_snapshot.exists():\n",
    "    shutil.copy(config_snapshot, f\"{download_dir}/config.yaml\")\n",
    "    print(f\"   ‚úÖ Config copied: config.yaml\")\n",
    "\n",
    "# Create summary\n",
    "summary = {\n",
    "    'run_name': session.run.name,\n",
    "    'config': selected_config,\n",
    "    'episodes': session.total_episodes,\n",
    "    'training_time_minutes': elapsed / 60,\n",
    "    'final_reward': session.metrics['episode_rewards'][-1],\n",
    "    'mean_reward': float(np.mean(session.metrics['episode_rewards'])),\n",
    "    'mean_lives_lost': float(np.mean(session.metrics['lives_lost'])),\n",
    "}\n",
    "with open(f\"{download_dir}/summary.json\", 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(f\"   ‚úÖ Summary created: summary.json\")\n",
    "\n",
    "# Create zip file\n",
    "print(\"\\nüóúÔ∏è  Creating zip archive...\")\n",
    "shutil.make_archive(download_dir, 'zip', download_dir)\n",
    "zip_file = f\"{download_dir}.zip\"\n",
    "\n",
    "print(f\"\\n‚úÖ Package ready: {zip_file}\")\n",
    "print(f\"   Size: {os.path.getsize(zip_file) / 1e6:.1f} MB\")\n",
    "\n",
    "# Download\n",
    "print(\"\\nüì• Downloading...\")\n",
    "files.download(zip_file)\n",
    "\n",
    "print(\"\\n‚úÖ Download complete!\")\n",
    "print(\"\\nüìã Next Steps:\")\n",
    "print(\"   1. Extract the zip file locally\")\n",
    "print(\"   2. Copy model.pt to your runs directory\")\n",
    "print(\"   3. Open dashboard ‚Üí Evaluation ‚Üí Load model.pt\")\n",
    "print(\"   4. Run evaluation and compare with other models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch-header"
   },
   "source": [
    "## üîÑ Batch Training (Optional)\n",
    "\n",
    "Train multiple configurations in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch-training"
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: Train multiple configs\n",
    "# Uncomment and modify as needed\n",
    "\n",
    "# configs_to_train = [\n",
    "#     'config/experiments/quick_test.yaml',\n",
    "#     'config/experiments/reward_tuning.yaml',\n",
    "# ]\n",
    "\n",
    "# for config_path in configs_to_train:\n",
    "#     print(f\"\\n{'='*60}\")\n",
    "#     print(f\"Training: {config_path}\")\n",
    "#     print(f\"{'='*60}\\n\")\n",
    "#     \n",
    "#     session = TrainingSession(config_path)\n",
    "#     session.add_callback(progress_callback)\n",
    "#     session.train()\n",
    "#     \n",
    "#     print(f\"‚úÖ Completed: {session.run.name}\")\n",
    "#     print(f\"   Final reward: {session.metrics['episode_rewards'][-1]:.2f}\")\n",
    "\n",
    "print(\"Batch training cell (commented out by default)\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}